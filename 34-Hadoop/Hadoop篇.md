## 什么是Hadoop

​	Hadoop 是一个由 Apache 软件基金会维护的开源软件框架，它允许使用简单的编程模型在大量计算机集群上处理和存储大规模数据集。Hadoop 的设计目标是在廉价硬件上实现高性能的大规模数据处理。

Hadoop 的核心组成部分包括：**Hadoop Distributed File System (HDFS)**、**MapReduce**

**1）HDFS产生背景**

​	随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切**需要一种系统来管理多台机器上的文件**，这就是分布式文件管理系统。**HDFS只是分布式文件管理系统中的一种。**

**2）HDFS定义**

​	**HDFS（Hadoop Distributed File System），它是一个文件系统**，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。

**HDFS的使用场景：适合一次写入，多次读出的场景**。一个文件经过创建、写入和关闭之后就不需要改变。

## Hadoop四高

1）高可靠性

Hadoop底层维护多个数据副本，所有即使hadoop某个计算元素或存储故障，也不会造成数据丢失

2）高扩展性

在集群间分配任务数据，可方便的扩展数以千计的节点

3）高效性

在mapreduce的思想下，Hadoop是可以并行工作的，以加快任务处理的速度。

4）高容错性

能够自动将失败的任务重新分配

## Hadoop组成

**Hadoop1.x阶段**

HDFS（数据存储）、MapReduce（计算+资源调度）、Common（辅助工具）

1.x时期，mr需要同时处理业务逻辑运算又要资源调度，压力大，耦合度大。

**Hadoop2.x阶段**

HDFS（数据存储）、MapReduce（计算）、**YARN（资源调度）**、Common（辅助工具）

**Hadoop3.x阶段无变化**

-   Hadoop集群包括两个：HDFS集群、YARN集群
-   两个集群逻辑上分离、通常物理上是在一起的
-   两个集群都是标准的主从架构的集群

## HDFS优缺点

**HDFS优点**

1）高容错性

​	数据自动保存多个副本。它通过增加副本的形式，提高容器性

​	某一个副本丢失后，它可以自动恢复

2）适合处理大数据

​	数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据

​	文件规模：能够处理百万规模以上的文件数量

3）可以**构建在廉价的机器上**，通过多副本机制，提高可靠性

**HDFS缺点**

1）**不适合低延迟数据访问**，比如毫秒级的存储数据，它做不到

2）**无法高效对大量小文件进行存储**

​	存储大量小文件，他会占用大量的NameNode大量的内存来存储文件目录和快信息。这样是不可取的，因为NameNode内存是有限的

​	小文件的寻址时间会超过读取时间，违反了HDFS的设计目标

3）**不支持并发写入、文件随机修改**

​	一个文件只能有一个写，不允许多个线程同时写

​	**仅支持数据追加（append），不支持文件的随机修改**



## Hadoop架构

### **HDFS 集群**

**NameNode**

​	主角色：NameNode（NN）是Master，它是管理者

-   存储文件**元数据**，如文件名、文件目录结构、文件属性，以及每个文件块列表、块所在DataNode等
-   管理HDFS的名称空间
-   配置副本策略
-   处理客户端读写请求

**MapReduce**

​	从角色：DataNode（DN） 是Slave，DataNode执行实际的操作

-   在本地文件系统**存储文件块数据**和读写数据块，以及**数据的校验和**

**Secondary NameNode**

主角色辅助角色：SecondaryNameNode（SNN）	相当于主角色的秘书

-   该节点**并非NameNode的热备节点**。当NameNode挂掉时，它并不能马上替换NameNode并提供服务
-   它只辅助NameNode，分担NameNode工作量，比如定期合并Fsimage和Edits，并推送给NameNode
-   **每个一段时间对NameNode元数据做备份**
-   紧急情况下，可辅助恢复NameNode

**Client客户端**

1）文件切片。文件上传HDFS时，Client将文件分成一个一个block，然后进行上传；

2）与NameNode交互，获取文件的位置信息；

3）与DataNode交互，读取或写入信息；

4）Client提供了一些命名来管理HDFS，比如NameNode格式化；

5）Client可以通过一些命名来访问HDFS，比如对HDFS增删改查等操作

### **YARN集群**

​	主角色：ResourceManager（RM）

-   整个集群资源（cpu、内存等）的老大

​	从角色：NodeManager（NM）

-   单个节点服务器资源的老大

​	ApplicationMaster（AM）

-   单个任务运行的老大

​	Container

-   容器，相当于一台独立的服务器，里面封装了任务运行时所需资源，内存、cpu、磁盘、网络等

注：集群上可以有很多ApplicationMaster，每个NodeManager上可以有多个Container

## Hadoop常用端口号

常用端口号

-   2.x	50070  8088	19888	9000/8020
-   3.x	9870	8088	19888	9820/9000/8020

## Hadoop常用配置

常用配置

-   2.x
    -   core-site.xml	hdfs-site.xml	mapred-site.xml	yarn-site.xml	slaves
-   3.x
    -   core-site.xml	hdfs-site.xml	mapred-site.xml	yarn-site.xml	workers



## HDFS文件块大小

HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数（dfs.blocksize）来设置，默认大小在Hadoop2.x/3.x版本是128M，3.x版本是64M

例如：

​	如果寻址时间为10ms，传输时间=10ms/0.01=1s（寻址时间为传输时间的1%为最佳），若目前磁盘传输速率为100MB/s，则block块大小 = 1s * 100MB/s = 100MB，所有块大小设置为128M比较合适

-   HDFS的块设置**太小，会增大寻址时间**（寻址时间大于传输时间），程序一直在找块的开始位置
-   HDFS的块设置**太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间**（传输时间远大于寻址时间），会导致处理数据非常慢
-   **寻址时间与传输时间的比例为1%时，为最佳状态**
-   HDFS的块大小设置主要取决于磁盘传输速率

小结：

-   1.x	64m
-   2.x 3.x    128m
-   
-   本地     32m      1.1倍
-   企业     128m 256m 512m
-   块大小取决于什么？
    -   磁盘的读写速度	
    -   普通机械硬盘    100m/s左右	==>	128m          
    -   普通的固态硬盘  200-300m/s	==>	256m
    -   高级的固态硬盘  500-600m/s	==>	512m

## HDFS小文件的危害

-   存储
    -   默认情况下，一个文件块不管多小都会占用NN 150字节左右。
    -   128m    一个文件块   ==>   150字节
    -   1字节    一个文件块   ==>   150字节     （小文件过多 浪费NN的存储内存）
    -   128g内存，能存储多少文件块？？
        -   128g * 1024m * 1024k * 1024字节 / = 9.1亿
-   计算
    -   默认情况下的切片规则，每个文件单独切片
    -   1字节  ==> 1个maptask  ==> 1g内存（小文件过多）
    -   128m  ==> 1个maptask  ==> 1g内存

## HDFS小文件怎么解决

-   har归档	本质是减少NN的存储压力

    -   打比方：在淘宝同一家店铺买了很多小玩意儿，他肯定会把它们一起打包发货

-   JVM重用（最多重用10次）

    开始	3s

    干活	2s

    .........

    干活	2s

    结束	3s

-   combineTextinputformat

    -   将多个文件放到一起统一切片，减少了maptask的个数，进而减少了集群内存
    -   比如（10个小文件）只需要（一个maptask）