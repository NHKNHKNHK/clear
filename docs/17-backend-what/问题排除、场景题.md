# 常识
## 



## 怎么分析JVM当前的内存占用情况？OOM后怎么分析？



## 你也没有排查过线上OOM的问题？如何排查？





## Spring Cloud Gateway 500问题排查？



## JDK序列化问题排查？



## 线上连接池爆满问题排查？



## Redis内存溢出了，你会怎么做？请说说排查思路和解决方案？



## 每次进入订单列表页面都会触发全量同步？



## 项目上有个导出excel场景发现很慢，怎么优化？



## 如何优化接口性能？（接口优化思路）

后端代码层面

-   利用缓存机制：使用了缓存就要考虑缓存与数据库数据不一致问题，以及缓存穿透、缓存击穿、缓存雪崩等常见问题。还要考虑缓存的分类，如二级缓存
-   并发调用：某个接口中如果调用了其他子系统，考虑是否可以改成并发调用
-   同步接口异步化
-   避免大事务
-   优化日志打印

数据库层面

-   数据库查询优化：如添加合适的索引、只查询必要的字段、避免深分页（比如查询时传入一个id，这一点需要与前端配合）
-   表设计冗余数据：反范式，可以减少多表关联查询
-   使用连接池管理数据库连接
-   使用数据压缩技术：这是针对网络数据传输的优化
-   如果优化查询、优化数据库配置等都达不到想要的效果，可能需要考虑更换其他类型的数据库



# 场景题

## 为什么POJO类布尔类型不要以is开头？

Java 开发中，POJO 类的布尔变量不应加 'is' 前缀，以免引起部分框架在序列化时的错误。由于部分框架（如：fastjson）依赖于JavaBean规范的get和set方法，不遵循规范可能导致访问问题。解决办法是使用属性名称直接作为方法名，以确保一致性。

>   阿里规约明确
>
>   ​	POJO中的任何布尔类型的变量不要加is前缀

例如

```java
@Data
public class Student implements Serializable {
    private String name;
    private boolan isMan;
}
```

如下使用，问题不大

```java
Student s = new Student();
s.setMan(true);
System.out.println(s.isMan()); // true	 注意这里是isMan，不是getMan
```

当使用fastjson进行序列化时

```java
Student s = new Student();
s.setMan(true);
System.out.println(JSON.toJSON(s)); // {"man":true}   注意这是的is前缀不见了
```

使用fastjson进行序列化时，发现布尔类型变量的`is`前缀不见了，因为根据JavaBean规范，isXxx会被认为是方法。而fastjson恰好遵循了JavaBean规范。

但我们使用其他序列化根据时，可以没有遵循JavaBean规范，例如：Gson

```java
Student s = new Student();
s.setMan(true);

Gson gson = new Gson();
System.out.println(gson.toJSON(s)); // {"isMan":true} 
```

演示一个错误的案例：

使用fastjson进行序列化，gson进行反序列化

```java
Student s = new Student();
s.setMan(true);

Gson gson = new Gson();
System.out.println(gson.fromJSON(JSON.toJSON(s), Student.class)); // Student(name=null, isMan=false)
```

因此，不建议在POJO类中使用is作为布尔类型的开头

**总结**

​	不同的序列化工具，对与布尔类型is的处理不同



## 为什么不推荐使用数据库自增主键？也不推荐使用UUID做主键？用雪花算法会存在哪些问题？

为什么不推荐使用数据库自增主键？以数据库id为例

如果单纯的基于表的自增id，如果说是单表业务，不会有多大问题，每条数据的id都能够唯一表示一行数据。当数量量大时，面临分库分表的时候，假设横向分了多个表，此时数据库表的自增id就无法无法确保数据的唯一性了。

当然你也可以使用**步长**去处理，假设分了3个表，一张表id自增是147，一张表id自增是258，一张表id自增是369，此时可以确保id的唯一性，但是当面临扩容的时候就会出现问题。例如，3张表变为4张表，此时工作量将是巨大的。

因此有了**分布式ID的解决方案**。比如是UUID，雪花算法。

但是**UUID也是不建议使用**的，这就要考虑InnoDB中索引的数据结构了

>   InnoDB默认是索引结构是B+树，它有一个概念就是：**索引即数据，数据即索引**。每张表默认都有一个主键索引树。主键索引树的叶子节点会完整的保存整行的数据，每个块就是一个page，默认16k。page页是内存跟磁盘交互的最小单位

第一它会**影响查询性能**，因为主键索引树中要存储大量的主键，而UUID比较长，占用的空间比较大，空间比较大，每行的数据也就越大，同样的数据量就需要更多的page页来承接，page页越多，索引树的高度也就越高，遍历的次数也就越多，遍历的page页也更多，表示与磁盘IO次数较多。第二就是**影响操作性能**，因为UUID是无序的、非趋势递增的，而主键索引树是需要排好序的，每次添加数据的时候都需要进行重排序（也叫树的分裂与合并），严重影响了操作数据的性能。所以开发中，应该尽量避免非趋势递增的主键id。

**雪花算法**它是由四部分组成的**64位**的二进制数据，然后转换为我们需要的十进制id。四部分分别是1bit符号位， 42bit的时间戳，10bit的机器id，12bit的序列号。时间戳、机器id、序列号三者确保了id的唯一性，也符合趋势递增。解决了UUID无需的问题，同时它又是一个64位的二进制，占用的空间小

但是他也存在一些问题：时间回拨问题、机器id管理问题、序列号一直（大部分）是0问题

**时间回拨问题**

因为雪花算法它生成id依赖于机器的时间戳，例如我们把系统的时间修改了，改成了过去的时间，就到导致id不是趋势递增的，甚至有可能出现id重复

**机器id管理问题**

在单台机器生成的时候没有问题，可以通过配置配置机器id，但是在集群部署时，假设有100台机器，那么要维护机器id是很难保证这个id不重复的，或者说很难维护，需要花费大量成本

**序列号一直（大部分）是0问题**

因为序列号的作用是在同一时间同一机器并发生成id时才会去递增，但是大部分场景下没有那么高的并发量，所以序列号一般就是0。

它存在什么问题呢？就是我们在取模，基于ID取模分库分表的场景，它可能会导致**数据的偏移**，因为0结尾取模一行一定会在偶数表内，这个时候可能很多的表是没有数据的。



**时间回拨问题解决思路**

-   直接抛出异常：牺牲可用性，当我们发现现在的时间戳比之前的id生成的时间戳还要小时，直接不在生成id，直接抛出异常
-   等待：当我们发现时间回拨问题时，直接等待时间恢复，并且设置一个最大的等待时间，如果超过等待时间直接抱错（这样子可以解决短时间内的时间回拨问题）
-   采用备用的方式：当我们发现时间回拨问题时，可以采用其他的机器id去生成，或者直接采用备用的一些方式去生成，比如说随机

**机器id管理问题解决思路**

-   配置文件：一般可以通过配置文件去配置，但是因为是人为操作，很难避免它是唯一的，并且也不好进行统一的管理
-   借助框架：比如说服务注册组件，服务注册他一定会有服务id，我们可以拿到注册中心的id。

**序列号一直（大部分）是0问题导致的分布分表数据不均匀解决思路**

-   解决思路是，当它是0的时候，去获取一个动态变化的值，比如说时间戳的最后一位，这样序列号会得到一个0或1的随机数



## 如何进行不停机数据迁移？



## 缓存预热

https://juejin.cn/post/7325441612401016851?searchId=202503221515451C26C3D0A1735275A174



## 如何设计一个支持10W QPS的评论中台？你会怎么设计？



## 如何设计一个支持10W QPS的会员系统？



## 如何设计一个秒杀功能？



## 如何设计一个RPC框架？



## 如何设计一个消息队列？



## 如何设计一个线程池？



## 如何设计一个短链系统？



## 如何设计一个HashMap？



## 如何设计一个文件上传系统？



## 如何设计一个点赞系统？

## 如何设计一个敏感词过滤系统？

## 为什么复杂的架构一定要做分层设计？


## 单点登录（SSO）的设计与实现？




## 设计一个订单号的生成服务，该如何设计？



## 热点商家交易订单的写入如何处理？



## 外部机构的API交互如何防止外部机构服务不可用拖垮调用服务？



## 两个动作。下订单和扣钱，如何保证只能扣一次钱？



## 搜索引擎设计：信息搜索怎么避免大海捞针？



## 如何根据应用场景选中合适的消息中间件？



## Redis的双机房部署方案？





## 对接第三方接口需要考虑什么？

**口语化**

很多人都是按照第三方接口文档去写代码，有些比较成熟的第三方接口还封装了工具类，使得大家很少去关注对接可能存在的一些问题

根据我个人的经验，主要考虑以下几个方面的问题：

安全性问题：和第三方接口对接时涉及到数据的跨网络传输，为了防止数据被拦截或篡改，需要采用安全的通信机制，比如使用https协议，以及通过数据签名来避免数据篡改的问题

接口的稳定性和可靠性：这两个方面会直接影响用户的体验和业务的正常流程，所以我们需要做相对充分的评估和测试

接口是否存在访问限制或费用：如果存在并发量限制，需要评估是否满足当前业务的需求。如果存在费用，需要评估是否满足我们的预算范围

以上



## 如果外部接口的RT无法保证，如何处理？



## 什么是限流？限流算法有哪些？怎么实现？



## 即时通信项目中，怎么实现历史消息的下拉分页加载？





## 让你实现一个分布式单例对象，怎么设计？



## 商家想要知道自己店铺最好的top50商品，如何实现？



## 朋友圈点赞功能实现？



## 抖音点赞功能实现？



## 分布式锁一般怎么实现？



## 如何设计一个分布式ID分号器？



## 如果让你统计每个接口每分钟调用的次数怎么统计？



## 线上消息队列故障，兜底改造方案？



## 一笔订单，在取消的那一刻用户刚好付款了，怎么办？



## 项目上发现出现很多重复订单，怎么处理？



## 线上发现Redis机器爆了，如何优化？



## 项目上需要导入一个几百万数据excel文件到数据库，有哪些注意点？



## 如果一笔订单，用户同时在微信和支付宝同时支付，会怎么样？



## 假设有一个1G大的HashMap，此时用户请求过来刚好触发它的扩容，会怎么样？怎么优化？



## 项目中如何设置远程调用的超时时间？



## 从网关再到各个微服务，如何设置RPC的超时时间。要考虑哪些问题？



## 如果没有内存限制，如何快速、安全地将1000亿条数据插入到HashMap中？



## 忘记密码后为什么是重置密码，而不是告知原密码？

因为服务端也无法得知原密码是啥

服务端在保存密码到数据库的时候，绝对不能直接铭文存储，铭文存储有以下风险:

-   数据库数据被盗风险
-   服务端相关人员恶意盗用等。。

通常我们将密码进行哈希加密，哈希算法是不可逆的，因此服务端也不知道我们的原密码是啥

常见的哈希算法：

-   MD5
-   SHA-256
-   Bcrypt

MD5，不同的密码加密后可能会产生相同的哈希值（即哈希冲突）

SHA-256，不同的密码加密后哈希冲突的可能性极低，比MD5抗碰撞性更强

MD5、SHA-256每次加密同一个密码都是固定的密文，可能存在暴力破解的风险，因此通常会采用SHA-256+盐的方式进行加密

>   盐：salt，即只要我们程序员才做到的字符串，可以有效的防止暴力破解

Bcrypt，自带盐，且每次加密盐都不一样，加密同一个密码可能得到的密文不一样，因此能够防止暴力破解



## 三次输错密码后，系统是这么做到不让我继续尝试的？





## 如何保证接口幂等性？



## 百万数据导出



## 10亿数据中如何实现URL去重？



## 多线程异步和MQ实现异步有什么区别？

>   本题主要考察
>
>   面试者对并发编程和分布式消息队列的理解
>
>   以及面试者如何考虑使用多线程异步和MQ来解决不同的问题

**口语化**

多线程异步和MQ实现异步在特性上有着异曲同工之妙，都支持程序的异步操作。

但是在实现上有着本质上的很大区别

1、处理任务的维度不同

多线程是进程内的一个概念，在一个进程中可以有多个线程并发处理任务；

MQ是分布式是消息队列，通过把消息发送到不同应用节点的不同进程来处理任务的，两者不在同一个维度上。

2、数据的可靠性不同

多线程异步处理任务的时候，数据是基于共享内存来进行交互的，一旦程序崩溃内存的数据会丢失；

而使用MQ可以利用MQ的持久化机制来保证消息的可靠性

3、分布式能力方面

MQ具备分布式能力，我们可以把消息分发到不同的节点存储和消费；

而多线程只能在一个进程中去处理任务



# 智商题

## 如何在2G大小的文件中，找出高频top100的单词？

>   这是一个`Top K`问题，面试过程中，可能会有很多变体
>
>   这类问题是典型的开放式题目，没有标准答案。

这个题目面临两个问题：

1、2G大小的文件，那就意味着无法一次性地加载到内存中

2、如果采用常规的思维，需要从这么大的文件中筛选，它会非常慢



我们可以采用**分割（分治）**的思想，将2G大小文件分割为每块大小512KB的小文件，那么就是2048个小文件。避免一次性读取整个文件造成内存不足的问题。

接着我们可以定义一个长度为2048的hash表数组，用来统计每个小文件中单词出现的频率。

我们还可以使用**多线程**去并发遍历2048个小文件，针对每个单词进行hash取模运算，分别存储到长度为2048的hash表数组中。

```java
int hash = Math.abs(word.hashCode() % hashTableSize);
hashTables[hash].merge(word, 1, Integer::sum);
```

接着我们遍历这个长度为2048的hash表数组，把频率为前100的单词存入到**小顶堆**中。小顶堆中的单词就是top100的单词





# 经验

## Lombok使用技巧

开发中，如果想使用Lombok建造者模式来set属性，如下：

```java
@Data
@Builder	// @Data @Builder 与同时使用时，需要加上无参、满参注解
@AllArgsConstructor	
@NoArgsConstructor
public class OssReq {
    @ApiModelProperty(value = "文件存储路径")
    private String filePath;
    @ApiModelProperty(value = "文件名")
    private String fileName;
    @ApiModelProperty(value = "请求的uid")
    private Long uid;
    @ApiModelProperty(value = "自动生成地址")
    @Builder.Default	// 切记！！！
    private boolean autoPath = true;
}
```

