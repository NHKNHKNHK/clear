# RDD 分区数目

分区是一个偏物理层的概念，也是 RDD 并行计算的核心。数据在 RDD 内部被切分为多个子集合，每个子集合可以被认为是一个分区，运算逻辑最小会被应用在每一个分区上，**每个分区是由一个单独的任务（task）来运行的，所以分区数越多，整个应用的并行度也会越高。** 

 获取RDD分区数目两种方式： 

```scala
// 方式一：
rdd.getNumPartitions

// 方式二：通过RDD获取
rdd.partitions.length
```

RDD分区的数据取决于哪些因素？ 

-   第一点：RDD分区的原则是使得分区的个数尽量等于集群中的CPU核心(core)数目，这样可以充分利用CPU的计算资源； 

-   第二点：在实际中为了更加充分的压榨CPU的计算资源，会把并行度设置为cpu核数的2~3倍； 

-   第三点：RDD分区数和启动时指定的**核数**、调用方法时指定的**分区数**、如文件**本身分区数**有关系，具体如下说明： 

    -   1）启动的时候指定的CPU核数确定了一个参数值: 
        -   spark.default.parallelism=指定的CPU核数(集群模式最小2) 
    -   2）对于Scala集合调用parallelize(集合,分区数)方法 
        -   如果没有指定分区数，就使用spark.default.parallelism 
        -   如果指定了就使用指定的分区数(不要指定大于spark.default.parallelism) 

    -   3）对于textFile(文件, 分区数) 

        -   defaultMinPartitions 

            -   如果没有指定分区数sc.defaultMinPartitions=min(defaultParallelism,2)  
            -   如果指定了就使用指定的分区数sc.defaultMinPartitions=指定的分区数rdd的分区数 

        -   rdd的分区数 

            -   对于本地文件 
                -   rdd的分区数 = max(本地file的分片数， sc.defaultMinPartitions) 
            -   对于HDFS文件 
                -   rdd的分区数 = max(hdfs文件的block数目， sc.defaultMinPartitions) 

            -   所以如果分配的核数为多个，且从文件中读取数据创建RDD，即使hdfs文件只有1个切片，最后的Spark的RDD的partition数也有可能是2

#  RDD并行度与分区

默认情况下，Spark可以将一个作业切分多个任务后，发送给Executor节点并行计算，而**能够并行计算的任务数量**我们称之为**并行度**。这个数量可以在构建RDD时指定。记住，**这里的并行执行的任务数量，并不是指的切分任务的数量**，不要混淆了。

-   读取内存数据时，数据可以按照并行度的设定进行数据的分区操作
-   读取文件数据时，数据是按照Hadoop文件读取的规则进行切片分区，而切片规则和数据读取的规则有些差异

在分布式程序中，网络通信开销很大，**Spark程序可以通过控制RDD分区方式来减少通信开销。**Spark中所有的RDD都可以进行分区，系统会根据一个针对键的函数对元素进行分区。虽然**Saprk不能控制每个键具体划分到哪个节点上，但是可以确保相同的键出现在同一个分区上。**

RDD的分区原则：

​	**分区的个数尽量等于集群中CPU核心（core）的数目**。对于不同的Spark部署模式而言，可通过设置 `spark.default.parallelism` 这个参数来配置默认的分区数目。各种模式下默认分区数目如下：

-   Local模式：默认为本地机器的cpu数目，若设置了local[n]，则默认为n
-   Standalone或Yarn模式：在 集群中所有cpu核数总和 与 2 这两者之间取较大者为默认值
-   Mesos模式：默认分区数为8

**Spark为RDD提供的两种分区方式：**

-   哈希分区（HashPartitioner）：是根据哈希值来分区
-   范围分区（RangePartitioner）：将一定范围的数据映射到一个分区中

此外，**Spark还支持自定义分区方式：**

-   即通过自定义的Partitioner对象来控制RDD的分区

    -   让自定义的类继承自`org.apache.spark.Partitioner`

    -   并实现其中抽象方法

    -   ```java
        public abstract int numPartitions()  // 用于返回创建的分区个数
            
        // 用于对输入的key做处理，并返回给key对应的分区ID
        // 分区ID范围 0 ~ numPartitions-1
        public abstract int getPartition(final Object key)  
        ```
