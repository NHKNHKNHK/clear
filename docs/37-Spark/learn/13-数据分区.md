# RDD分区器

在分布式程序中，通信的代价是很大的，因此控制数据分布以获得最少的网络传输可以极大的提升整体性能

Spark程序可以通过控制RDD分区方式来减少通信开销。

Spark中**所有的 Pair RDD 都可以进行分区**。Spark是通过对每个Pair RDD 中的键应用某一种方法来进行分区。

Spark目前支持**Hash分区**和**Range分区**，和**用户自定义分区**。

Hash分区为当前的默认分区。

分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle后进入哪个分区，进而决定了Reduce的个数。

-   ​	**只有Key-Value类型的RDD才有分区器**，非Key-Value类型的RDD分区的值是None
-   ​	每个RDD的分区ID范围：0 ~ (numPartitions - 1)，决定这个值是属于那个分区的。

## 分区说明

Spark 的 Java 、Python API 都和Scala一样，可以从数据分区中获益。

不过Python中，我们不能将 HashPartitioner 对象传给partitionBy算子，而只需要把具体分区数传入即可。例如，rdd.partitionBy(100)。

## 获取RDD的分区方式

在Scala、Java中，我们可以使用RDD的 paritioner 属性（Java 中使用 partitioner()方法）来获取RDD的分区方式。它会返回一个 `Scala.Option` 对象。

说明：

​	在Scala中，Scala.Option是用来存放对象的容器类。它可以调用 isDefind() 方法来检查是否有值，调用 get() 来获取其中的值（值存在的话，是一个scala.Partitioner对象）。

演示：

```scala
val sc =  new SparkContext(new SparkConf().setAppName("分区"))
val pairs = sc.parallelize(List((1, 1), (2, 2), (3, 3)))
// 初始时没有分区方式信息（所有 Option[Partitioner] = None）
val partitioner = pairs.partitioner  // None
println(partitioner)
pairs.partitionBy(new HashPartitioner(2))
val partitioner2 = pairs.partitioner
println(partitioner2)
```



## Hash分区

**Hash分区**：对于给定的key，计算其hashCode,并除以分区个数取余

```java
// Hash分区Java源码如下
public class HashPartitioner extends Partitioner {
    private final int partitions;

    public int numPartitions() {
        return this.partitions;
    }

    public int getPartition(final Object key) {
        int var2;
        if (key == null) {
            var2 = 0;
        } else {
            var2 = .MODULE$.nonNegativeMod(key.hashCode(), this.numPartitions());
        }

        return var2;
    }

    public boolean equals(final Object other) {
        boolean var2;
        if (other instanceof HashPartitioner) {
            HashPartitioner var4 = (HashPartitioner)other;
            var2 = var4.numPartitions() == this.numPartitions();
        } else {
            var2 = false;
        }

        return var2;
    }

    public int hashCode() {
        return this.numPartitions();
    }

    public HashPartitioner(final int partitions) {
        this.partitions = partitions;
        scala.Predef..MODULE$.require(partitions >= 0, () -> {
            return (new StringBuilder(43)).append("Number of partitions (").append(this.partitions).append(") cannot be negative.").toString();
        });
    }
}
```

## Range分区

**Range分区**：将一定范围内的数据映射到一个分区中，尽量保证每个分区数据均匀，而且分区间有序

```
// Range分区源码太多了，这里就不放了
```

## 自定义分区

Spark提供的 HashPartitioner 与 RangePartitioner 在大多数情况下都已经够用了，特殊情况下，Spark还支持自定义分区。

**自定义分区步骤：**

-   自定义分区类，让自定义的类继承自`org.apache.spark.Partitioner`
-   并实现其中抽象方法
    -   numPartitions: Int：返回创建出来的分区数
    -   getPartition(key: Any): Int：返回给定键的分区编号（0 到 numPartitions-1）
    -   equals()：Java中判断相等性的标准方法。这个方法非常重要，Spark需要用到这个方法来检查你的分区器对象是否和其他分区器实例相同，这样Spark才可以判断两个RDD的分区方式是否相同。

注意：

​	但你的算法依赖于Java中的 hashCode()方法时，可能会返回负数。所有我们需要谨慎对待，确保getPartition方法永远返回一个非负数。

**自定义分区的使用：**

​	自定义分区器使用非常简单，只需要把分区器实例传递给partitionBy算子即可。

​	Spark提供了很多依赖于shuffle的算子，比如 join()、groupByKey()等等，将自定义分区器实例传递给它们也是可以的。

### Scala演示：

```scala
class DomainNamePartition(numParts: Int) extends Partitioner {
  override def numPartitions: Int = numParts

  override def getPartition(key: Any): Int = {
    val domain = new java.net.URL(key.toString).getHost
    val code = (domain.hashCode % numPartitions)
    // 如果 code为 0，我们要让它始终返回非0数
    if (code < 0) code + numPartitions else code
  }

  // 用来让Spark区分分区函数对象的Java equals方法
  override def equals(other: Any): Boolean = other match {
    case dnp: DomainNamePartition =>
      dnp.numPartitions == numPartitions
    case _ =>
      false
  }
}
```

注意：

​	在equals()方法中，使用Scala的模式匹配操作符（match）来检查 other 是否是 ，并在成立时自动进行类型转换。这个Java中的 instanceof()是一样的。



### Java演示：

```java
public class SparkRDD_Partitioner {
    public static void main(String[] args) {
        SparkConf sparkConf = new SparkConf().setAppName("演示自定义分区").setMaster("local[*]");
        JavaSparkContext sparkContext = new JavaSparkContext(sparkConf);
        JavaRDD<String> RDD = sparkContext.parallelize(Arrays.asList("nba", "cba", "wnba"));
        JavaPairRDD<String, Integer> pairRDD = RDD.mapToPair(n -> new Tuple2<>(n, 666));

        JavaPairRDD<String, Integer> result = pairRDD.partitionBy(new MyPartitioner());
        result.saveAsTextFile("file:///opt/temp/qiu");

        sparkContext.stop();
    }
}


/**
 * 自定义分区器
 * 1.继承 Partitioner
 * 2.重写方法
 */
class MyPartitioner extends Partitioner {

    /**
     * 分区数量
     *
     * @return
     */
    @Override
    public int numPartitions() {
        return 4;
    }

    /**
     * @param key
     * @return 根据数据的key值返回数据所在的分区索引（从0开始）
     */
    @Override
    public int getPartition(Object key) {
        if ("nba".equals(key)) {
            return 0;
        } else if ("cba".equals(key)) {
            return 1;
        } else if ("wnba".equals(key)) {
            return 2;
        } else {
            return 3;
        }
    }
}
```

结果

```shell
[root@kk01 qiu]# pwd
/opt/temp/qiu
[root@kk01 qiu]# ll
total 12
-rw-r--r--. 1 root root 10 May  5 10:20 part-00000
-rw-r--r--. 1 root root 10 May  5 10:20 part-00001
-rw-r--r--. 1 root root 11 May  5 10:20 part-00002
-rw-r--r--. 1 root root  0 May  5 10:20 part-00003
-rw-r--r--. 1 root root  0 May  5 10:20 _SUCCESS
[root@kk01 qiu]# cat part-00000
(nba,666)
[root@kk01 qiu]# cat part-00001
(cba,666)
[root@kk01 qiu]# cat part-00002
(wnba,666)
[root@kk01 qiu]# cat part-00003

```

