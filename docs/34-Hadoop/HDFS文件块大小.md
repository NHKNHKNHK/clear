# HDFS文件块大小

HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数（dfs.blocksize）来设置，默认大小在Hadoop2.x/3.x版本是128M，3.x版本是64M

例如：

​	如果寻址时间为10ms，传输时间=10ms/0.01=1s（寻址时间为传输时间的1%为最佳），若目前磁盘传输速率为100MB/s，则block块大小 = 1s * 100MB/s = 100MB，所有块大小设置为128M比较合适

-   HDFS的块设置**太小，会增大寻址时间**（寻址时间大于传输时间），程序一直在找块的开始位置
-   HDFS的块设置**太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间**（传输时间远大于寻址时间），会导致处理数据非常慢
-   **寻址时间与传输时间的比例为1%时，为最佳状态**
-   HDFS的块大小设置主要取决于磁盘传输速率

## 小结

-   1.x	64m
-   2.x 3.x    128m
-   
-   本地     32m      1.1倍
-   企业     128m 256m 512m
-   块大小取决于什么？
    -   磁盘的读写速度	
    -   普通机械硬盘    100m/s左右	==>	128m          
    -   普通的固态硬盘  200-300m/s	==>	256m
    -   高级的固态硬盘  500-600m/s	==>	512m
