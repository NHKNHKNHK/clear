## 消息队列消息没有消费成功怎么办？


## Kafka如何保证消息不丢、重复发了怎么办？

## Kafka为什么会出现重复消费？如何解决？

**口语化**

Kafka Broker中每个分区存储的消息都有一个offset标记，Kafka的消费者是通过offset这个标记来维护当前已经消费的数据，消费者每消费一批数据，Kafka Broker就会更新offset的值， 避免重复消费的问题。

默认情况下，消息消费完毕后会自动提交offset，避免重复消费。

Kakfa的消费端自动提交offset的时间间隔是5s

`enable.auto.commit=true`  ` auto.commit.interval.ms=5000`

如果在这5s后，应用程序宕机或强制kill掉，offset未来得及提交，就可能会出现重复消费的问题。





### Kafka消息重复消费的原因

1.  **消费者组重新分配（Rebalance）**
    -   当消费者实例意外宕机或重启时，Kafka会触发一次再平衡操作，重新分配分区。如果在再平衡期间，消费者已经处理了消息但还没有提交偏移量，那么在再平衡后，新的消费者可能会从之前的偏移量开始读取消息，导致重复消费。
2.  **手动提交偏移量**
    -   如果消费者配置为手动提交偏移量，并且在处理完消息之后但在提交偏移量之前发生故障，那么当该消费者恢复时，它将从上次提交的偏移量处继续消费，从而导致重复消费。
3.  **生产者重试机制**
    -   生产者发送消息失败时，Kafka允许生产者进行重试。如果网络问题导致生产者未收到确认，生产者可能会重复发送同一消息，即使该消息实际上已经被成功接收并处理。
4.  **Kafka Broker 故障**
    -   当 Kafka 集群中的 broker 发生故障时，可能会导致消息丢失或重复，进而引发消费者端的消息重复消费问题。

### 解决Kafka消息重复消费的方案

1.  **幂等性处理**
    -   在消费端实现幂等逻辑，确保即使同一条消息被多次处理，业务结果也是一致的。例如，可以使用数据库唯一索引、检查业务逻辑条件或持久化存储消息ID等方式来保证幂等性。
2.  **自动提交偏移量**
    -   尽量避免手动提交偏移量，而是选择自动提交偏移量。自动提交可以在一定程度上减少由于消费者故障导致的重复消费问题。
3.  **精确一次性语义（Exactly-Once Semantics, EOS）**
    -   使用 Kafka 提供的 EOS 功能，它可以确保消息在生产、传输和消费过程中只被处理一次。EOS 是通过事务机制实现的，保证消息生产和消费的原子性。
4.  **优化生产者配置**
    -   调整生产者的 `retries` 和 `acks` 参数，以减少因网络问题导致的重复发送。同时，合理设置 `max.in.flight.requests.per.connection` 参数，防止未确认的消息过多。
5.  **监控与报警**
    -   建立完善的监控体系，及时发现和处理可能导致重复消费的问题，如消费者异常退出、broker故障等。
6.  **使用分布式锁或状态协调服务**
    -   对于某些特定场景，可以引入分布式锁或状态协调服务（如 Zookeeper 或其他一致性协议），确保同一时间只有一个消费者处理某条消息。
7.  **调整再平衡策略**
    -   通过调整消费者的配置参数（如 `session.timeout.ms` 和 `heartbeat.interval.ms`），可以优化再平衡过程，减少不必要的再平衡触发











## 为什么不建议使用MQ实现订单到期关闭？

回顾一下利用MQ实现订单的到期（具体查看场景题篇）

-   kafka（MQ 方案不推荐，大量无效调度）
-   RocketMQ延迟消息（MQ 方案不推荐，大量无效调度）
-   RabbitMQ死信队列（MQ 方案不推荐，大量无效调度）
-   RabbitMQ插件（MQ 方案不推荐，大量无效调度）

但是，其实用MQ的延迟消息实现订单的到期关闭并不是一种特别好的方案，尤其是在数据量比较大的情况下。主要存在以下几个问题：

-   **资源占用与成本**：如果系统中存在大量订单，为每一个订单都创建一个延迟消息可能会导致消息队列中**积压大量的消息**，这不仅增加了消息队列的资源消耗，也可能导致增加成本，尤其是在使用云服务提供商的消息队列服务时。

-   **延迟消息的限制（重要）**：首先并不是所有的消息队列服务都支持延迟消息，即使有一些支持，也可能对消息的延迟时间有限制。
    -   例如，某些服务可能限制延迟时间的最大值，这可能无法满足所有订单的到期关闭需求。
    -   （尤其是一些B类采购订单，关闭时间可能会比较长）

-   **可靠性问题（重要）**：虽然消息队列一般来说可靠性较高，但是也没办法做到100%不丢消息，所以在极端情况下，会有丢消息的风险。

-   **精确性问题**：消息的投递延迟是比较常见的一种情况，这可能会导致订单关闭操作不够精确。

-   **大量无效消息（重要）**：使用MQ实现订单到期关闭，就要把订单放到MQ中，但是大部分订单会提前取消或者完成支付，这就会导致很多无效的消息。

-   **扩展性问题**：随着系统规模的扩大，依赖于消息队列的延迟消息来处理订单到期可能遇到扩展性问题。系统可能需要更复杂的消息队列管理策略和更高效的资源利用策略来应对不断增长的订单量。

这里尤其是**可靠性及无效消息的问题比较明显**，所以在一个订单量比较大的场景，不是特别建议用MQ实现订单的到期关闭。

一般是通过定时任务来实现，比如阿里内部就搞了个TOC（超时中心），就是基于定时任务来实现的订单到期关闭。

