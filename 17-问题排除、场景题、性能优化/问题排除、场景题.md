# 常识

## QPS、TPS、RT、吞吐量这些高并发性能指标？

**QPS (Queries Per Second)**:

-   指的是每秒钟系统能够处理的查询数量。
-   通常用来衡量服务器响应客户端请求的能力。
-   在Web应用中，这可以表示每秒内服务器成功处理了多少次HTTP请求。

**TPS (Transactions Per Second)**:

-   表示每秒钟系统能够处理的事务数量。
-   事务可以是一个完整的业务操作，例如一次数据库操作或一系列相关操作的组合。
-   对于某些系统来说，TPS和QPS可能是相同的，但在涉及多步骤操作的情况下，TPS可能会小于QPS。

**RT (Response Time)**:

-   响应时间指的是系统从接收请求到完成处理并返回响应所需的时间。
-   这个时间通常包括网络延迟、处理时间和可能的数据传输时间。
-   RT是衡量系统性能的一个重要指标，因为它直接影响用户体验。

**吞吐量**:

-   吞吐量通常指的是单位时间内系统能够处理的数据总量或请求总数。
-   它可以用来描述网络带宽、服务器处理能力等多种情况下的数据处理能力。
-   吞吐量有时可以与QPS或TPS等同使用，但更广泛地涵盖了系统整体的数据处理能力。



>   QPS = 并发数 / 平均响应时间



## 如何避免超预期的高并发压力压垮系统？


## CPU飙高系统反应慢怎么排查？



## 怎么分析JVM当前的内存占用情况？OOM后怎么分析？



## 你也没有排查过线上OOM的问题？如何排查？





## Spring Cloud Gateway 500问题排查？



## JDK序列化问题排查？



## 线上连接池爆满问题排查？



## Redis内存溢出了，你会怎么做？请说说排查思路和解决方案？



## 每次进入订单列表页面都会触发全量同步？



## 项目上有个导出excel场景发现很慢，怎么优化？



# 场景题

## 为什么POJO类布尔类型不要以is开头？

Java 开发中，POJO 类的布尔变量不应加 'is' 前缀，以免引起部分框架在序列化时的错误。由于部分框架（如：fastjson）依赖于JavaBean规范的get和set方法，不遵循规范可能导致访问问题。解决办法是使用属性名称直接作为方法名，以确保一致性。

>   阿里规约明确
>
>   ​	POJO中的任何布尔类型的变量不要加is前缀

例如

```java
@Data
public class Student implements Serializable {
    private String name;
    private boolan isMan;
}
```

如下使用，问题不大

```java
Student s = new Student();
s.setMan(true);
System.out.println(s.isMan()); // true	 注意这里是isMan，不是getMan
```

当使用fastjson进行序列化时

```java
Student s = new Student();
s.setMan(true);
System.out.println(JSON.toJSON(s)); // {"man":true}   注意这是的is前缀不见了
```

使用fastjson进行序列化时，发现布尔类型变量的`is`前缀不见了，因为根据JavaBean规范，isXxx会被认为是方法。而fastjson恰好遵循了JavaBean规范。

但我们使用其他序列化根据时，可以没有遵循JavaBean规范，例如：Gson

```java
Student s = new Student();
s.setMan(true);

Gson gson = new Gson();
System.out.println(gson.toJSON(s)); // {"isMan":true} 
```

演示一个错误的案例：

使用fastjson进行序列化，gson进行反序列化

```java
Student s = new Student();
s.setMan(true);

Gson gson = new Gson();
System.out.println(gson.fromJSON(JSON.toJSON(s), Student.class)); // Student(name=null, isMan=false)
```

因此，不建议在POJO类中使用is作为布尔类型的开头

**总结**

​	不同的序列化工具，对与布尔类型is的处理不同



## 为什么不推荐使用数据库自增主键？也不推荐使用UUID做主键？用雪花算法会存在哪些问题？

为什么不推荐使用数据库自增主键？以数据库id为例

如果单纯的基于表的自增id，如果说是单表业务，不会有多大问题，每条数据的id都能够唯一表示一行数据。当数量量大时，面临分库分表的时候，假设横向分了多个表，此时数据库表的自增id就无法无法确保数据的唯一性了。

当然你也可以使用**步长**去处理，假设分了3个表，一张表id自增是147，一张表id自增是258，一张表id自增是369，此时可以确保id的唯一性，但是当面临扩容的时候就会出现问题。例如，3张表变为4张表，此时工作量将是巨大的。

因此有了**分布式ID的解决方案**。比如是UUID，雪花算法。

但是**UUID也是不建议使用**的，这就要考虑InnoDB中索引的数据结构了

>   InnoDB默认是索引结构是B+树，它有一个概念就是：**索引即数据，数据即索引**。每张表默认都有一个主键索引树。主键索引树的叶子节点会完整的保存整行的数据，每个块就是一个page，默认16k。page页是内存跟磁盘交互的最小单位

第一它会**影响查询性能**，因为主键索引树中要存储大量的主键，而UUID比较长，占用的空间比较大，空间比较大，每行的数据也就越大，同样的数据量就需要更多的page页来承接，page页越多，索引树的高度也就越高，遍历的次数也就越多，遍历的page页也更多，表示与磁盘IO次数较多。第二就是**影响操作性能**，因为UUID是无序的、非趋势递增的，而主键索引树是需要排好序的，每次添加数据的时候都需要进行重排序（也叫树的分裂与合并），严重影响了操作数据的性能。所以开发中，应该尽量避免非趋势递增的主键id。

**雪花算法**它是由四部分组成的**64位**的二进制数据，然后转换为我们需要的十进制id。四部分分别是1bit符号位， 42bit的时间戳，10bit的机器id，12bit的序列号。时间戳、机器id、序列号三者确保了id的唯一性，也符合趋势递增。解决了UUID无需的问题，同时它又是一个64位的二进制，占用的空间小

但是他也存在一些问题：时间回拨问题、机器id管理问题、序列号一直（大部分）是0问题

**时间回拨问题**

因为雪花算法它生成id依赖于机器的时间戳，例如我们把系统的时间修改了，改成了过去的时间，就到导致id不是趋势递增的，甚至有可能出现id重复

**机器id管理问题**

在单台机器生成的时候没有问题，可以通过配置配置机器id，但是在集群部署时，假设有100台机器，那么要维护机器id是很难保证这个id不重复的，或者说很难维护，需要花费大量成本

**序列号一直（大部分）是0问题**

因为序列号的作用是在同一时间同一机器并发生成id时才会去递增，但是大部分场景下没有那么高的并发量，所以序列号一般就是0。

它存在什么问题呢？就是我们在取模，基于ID取模分库分表的场景，它可能会导致**数据的偏移**，因为0结尾取模一行一定会在偶数表内，这个时候可能很多的表是没有数据的。



**时间回拨问题解决思路**

-   直接抛出异常：牺牲可用性，当我们发现现在的时间戳比之前的id生成的时间戳还要小时，直接不在生成id，直接抛出异常
-   等待：当我们发现时间回拨问题时，直接等待时间恢复，并且设置一个最大的等待时间，如果超过等待时间直接抱错（这样子可以解决短时间内的时间回拨问题）
-   采用备用的方式：当我们发现时间回拨问题时，可以采用其他的机器id去生成，或者直接采用备用的一些方式去生成，比如说随机

**机器id管理问题解决思路**

-   配置文件：一般可以通过配置文件去配置，但是因为是人为操作，很难避免它是唯一的，并且也不好进行统一的管理
-   借助框架：比如说服务注册组件，服务注册他一定会有服务id，我们可以拿到注册中心的id。

**序列号一直（大部分）是0问题导致的分布分表数据不均匀解决思路**

-   解决思路是，当它是0的时候，去获取一个动态变化的值，比如说时间戳的最后一位，这样序列号会得到一个0或1的随机数



## 如何进行不停机数据迁移？



## 如何设计一个支持10W QPS的评论中台？你会怎么设计？



## 如何设计一个支持10W QPS的会员系统？



## 如何设计一个秒杀功能？



## 如何设计一个RPC框架？



## 如何设计一个消息队列？



## 如何设计一个线程池？



## 如何设计一个短链系统？



## 如何设计一个HashMap？



## 如何设计一个文件上传系统？



## 如何设计一个点赞系统？

## 如何设计一个敏感词过滤系统？

## 为什么复杂的架构一定要做分层设计？


## 单点登录（SSO）的设计与实现？




## 设计一个订单号的生成服务，该如何设计？



## 热点商家交易订单的写入如何处理？



## 外部机构的API交互如何防止外部机构服务不可用拖垮调用服务？



## 两个动作。下订单和扣钱，如何保证只能扣一次钱？



## 搜索引擎设计：信息搜索怎么避免大海捞针？



## 如何根据应用场景选中合适的消息中间件？



## Redis的双机房部署方案？





## 对接第三方接口需要考虑什么？

**口语化**

很多人都是按照第三方接口文档去写代码，有些比较成熟的第三方接口还封装了工具类，使得大家很少去关注对接可能存在的一些问题

根据我个人的经验，主要考虑以下几个方面的问题：

安全性问题：和第三方接口对接时涉及到数据的跨网络传输，为了防止数据被拦截或篡改，需要采用安全的通信机制，比如使用https协议，以及通过数据签名来避免数据篡改的问题

接口的稳定性和可靠性：这两个方面会直接影响用户的体验和业务的正常流程，所以我们需要做相对充分的评估和测试

接口是否存在访问限制或费用：如果存在并发量限制，需要评估是否满足当前业务的需求。如果存在费用，需要评估是否满足我们的预算范围

以上



## 如果外部接口的RT无法保证，如何处理？



## 什么是限流？限流算法有哪些？怎么实现？



## 即时通信项目中，怎么实现历史消息的下拉分页加载？



## 让你实现一个订单超时取消，怎么设计？

话，就需要把之前的订单（支付单）取消掉。这种类似的场景有很多，还有比如到期自动收货、超时自动退款、下单后自动发送短信等等都是类似的业务问题。



订单的到期关闭的实现有很多种方式，分别有：

-   被动关闭（不推荐）
-   定时任务（**推荐**，适合时间精确度要求不高的场景，如果数据量大可能会对数据库造成一定压力）
-   DelayQueue（不推荐，基于内存，无法持久化）
-   时间轮（不推荐，基于内存，无法持久化）
-   kafka（MQ 方案不推荐，大量无效调度）
-   RocketMQ延迟消息（MQ 方案不推荐，大量无效调度）
-   RabbitMQ死信队列（MQ 方案不推荐，大量无效调度）
-   RabbitMQ插件（MQ 方案不推荐，大量无效调度）
-   Redis过期监听（不推荐，容易丢消息）
-   Redis的ZSet（不推荐，可能会重复消费，因此需要加锁，做好幂等性）
-   Redisson（**推荐**，可以用）

**实现的复杂度上（包含用到的框架的依赖及部署）：**

Redisson > RabbitMQ插件 > RabbitMQ死信队列 > RocketMQ延迟消息 ≈ Redis的zset > Redis过期监听 ≈ kafka时间轮 > 定时任务 > Netty的时间轮 > JDK自带的DelayQueue > 被动关闭

不同的场景中也适合不同的方案：

-   自己玩玩：被动关闭 
-   单体应用，业务量不大：Netty的时间轮、JDK自带的DelayQueue、定时任务 
-   分布式应用，业务量不大：Redis过期监听、RabbitMQ死信队列、Redis的zset、定时任务 
-   分布式应用，业务量大、并发高：Redisson、RabbitMQ插件、kafka时间轮、RocketMQ延迟消息、定时任务 
-   业务量特别大：定时任务

总体考虑的话，考虑到成本，方案完整性、以及方案的复杂度，还有用到的第三方框架的流行度来说，个人比较建议优先考虑定时任务、Redisson+Redis、RabbitMQ插件、RocketMQ延迟消息等方案。

**但是，如果考虑到订单到期关闭的业务特点，如果在订单量特别大的时候，MQ其实并不适合**：



**被动关闭**

在解决这类问题的时候，有一种比较简单的方式，那就是通过业务上的被动方式来进行关单操作。

简单点说，就是订单创建好了之后。我们系统上不做主动关单，什么时候用户来访问这个订单了，再去判断时间是不是超过了过期时间，如果过了时间那就进行关单操作，然后再提示用户

优点：

-   这种做法是最简单的，基本不需要开发定时关闭的功能

缺点：

-   如果用户一直不来查看这个订单，那么就会有很多脏数据冗余在数据库中一直无法被关单。

-   需要在用户的查询过程中进行写的操作，一般写操作都会比读操作耗时更长，而且有失败的可能，一旦关单失败了，就会导致系统处理起来比较复杂。

所以，**这种方案只适合于自己学习的时候用，任何商业网站中都不建议使用这种方案来实现订单关闭的功能。**



**定时任务**

具体实现细节就是我们通过一些调度平台来实现定时执行任务，任务就是去扫描所有到期的订单，然后执行关单动作。	

例如：基于Timer、ScheduledThreadPoolExecutor、或者像xxl-job这类调度框架都能实现

缺点：

-   **1、时间不精准。** 一般定时任务基于固定的频率、按照时间定时执行的，那么就可能会发生很多订单已经到了超时时间，但是定时任务的调度时间还没到，那么就会导致这些订单的实际关闭时间要比应该关闭的时间晚一些。

-   **2、无法处理大订单量。** 定时任务的方式是会把本来比较分散的关闭时间集中到任务调度的那一段时间，如果订单量比较大的话，那么就可能导致任务执行时间很长，整个任务的时间越长，订单被扫描到时间可能就很晚，那么就会导致关闭时间更晚。

-   **3、对数据库造成压力。** 定时任务集中扫表，这会使得数据库IO在短时间内被大量占用和消耗，如果没有做好隔离，并且业务量比较大的话，就可能会影响到线上的正常业务。

-   **4、分库分表问题。** 订单系统，一旦订单量大就可能会考虑分库分表，在分库分表中进行全表扫描，这是一个极不推荐的方案。

这些问题的解决方案如下：

​	[定时任务扫表的方案有什么缺点？](../04-Java并发篇/Java并发篇.md##sss)

所以，**定时任务的方案，适合于对时间精确度要求不高、并且业务量不是很大的场景中。如果对时间精度要求比较高，这种方案不适用。（但是一般来说，订单的到期关闭这种业务，对时间精确度要求并不高，所以定时任务也是使用的最广泛的一种方案！）**



**JDK自带的DelayQueue**

基于JDK自带的DelayQueue来实现，不需要借助任何外部的资源，直接基于应用自身就能实现

>   DelayQueue是一个无界的BlockingQueue，用于放置实现了Delayed接口的对象，其中的对象只能在其到期时才能从队列中取走。

基于延迟队列，是可以实现订单的延迟关闭的，首先，在用户创建订单的时候，把订单加入到DelayQueue中，然后，还需要一个常驻任务不断的从队列中取出那些到了超时时间的订单，然后在把他们进行关单，之后再从队列中删除掉。

这个方案需要有一个线程，不断的从队列中取出需要关单的订单。一般在这个线程中需要加一个while(true)循环，这样才能确保任务不断的执行并且能够及时的取出超时订单。

优点：

-   实现起来简单，不须要依赖第三方的框架和类库，JDK原生就支持了

缺点：

-   **可能会导致OOM**：基于DelayQueue的话，需要把订单放进去，那如果订单量太大的话，可能会导致OOM的问题

-   **无法持久化**：DelayQueue是基于JVM内存的，一旦机器重启了，里面的数据就都没有了。虽然我们可以配合数据库的持久化一起使用。

-   **集群环境不可用**：现在很多应用都是集群部署的，那么集群中多个实例上的多个DelayQueue如何配合是一个很大的问题。

所以，**基于JDK的DelayQueue方案只适合在单机场景、并且数据量不大的场景中使用，如果涉及到分布式场景，那还是不建议使用。**



**Netty的时间轮**

与JDK自带的DelayQueue类似的方式，那就是基于时间轮实现。

为什么要有时间轮呢？主要是因为DelayQueue插入和删除操作的平均时间复杂度——O(nlog(n))，虽然已经挺好的了，但是时间轮的方案可以将插入和删除操作的时间复杂度都降为O(1)。

>   时间轮可以理解为一种环形结构，像钟表一样被分为多个 slot。每个 slot 代表一个时间段，每个 slot 中可以存放多个任务，使用的是链表结构保存该时间段到期的所有任务。时间轮通过一个时针随着时间一个个 slot 转动，并执行 slot 中的所有到期任务。

![](./assets/1716990730744-1095254c-6a51-44be-8a37-972eb062a3eb-845243.jpeg)

基于Netty的HashedWheelTimer可以帮助我们快速的实现一个时间轮，这种方式和DelayQueue类似

缺点都是基于内存、集群扩展麻烦、内存有限制等等。

所以，**基于Netty的时间轮方案比基于JDK的DelayQueue效率更高，实现起来更简单，但是同样的，只适合在单机场景、并且数据量不大的场景中使用，如果涉及到分布式场景，那还是不建议使用。**



**Kafka的时间轮**

既然基于Netty的时间轮存在一些问题，那么有没有其他的时间轮的实现呢？

还真有的，那就是Kafka的时间轮，Kafka内部有很多延时性的操作，如延时生产，延时拉取，延时数据删除等，这些延时功能由内部的延时操作管理器来做专门的处理，其底层是采用时间轮实现的。

而且，为了解决有一些时间跨度大的延时任务，Kafka 还引入了层级时间轮，能更好控制时间粒度，可以应对更加复杂的定时任务处理场景；

Kafka 中的时间轮的实现是 TimingWheel 类，位于 `kafka.utils.timer` 包中。基于Kafka的时间轮同样可以得到O(1)时间复杂度，性能上还是不错的。

**基于Kafka的时间轮的实现方式，在实现方式上有点复杂，需要依赖kafka，但是他的稳定性和性能都要更高一些，而且适合用在分布式场景中。**



**RocketMQ延迟消息**

相比于Kafka来说，RocketMQ中有一个强大的功能，那就是支持延迟消息。

>   RocketMQ，相比于Kafka，在架构上做了减法，在功能上做了加法，例如：延迟消息功能
>
>   延迟消息，当消息写入到Broker后，不会立刻被消费者消费，需要等待指定的时长后才可被消费处理的消息，称为延时消息。

有了延迟消息，我们就可以在订单创建好之后，发送一个延迟消息，比如20分钟取消订单，那就发一个延迟20分钟的延迟消息，然后在20分钟之后，消息就会被消费者消费，消费者在接收到消息之后，去关单就行了。

缺点：

-   但是，RocketMQ的延迟消息并不是支持任意时长的延迟的，它只支持：`1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h`这几个时长。（商业版支持任意时长）

可以看到，有了RocketMQ延迟消息之后，我们处理上就简单很多，只需要发消息，和接收消息就行了，系统之间完全解耦了。但是因为延迟消息的时长受到了限制，所以并不是很灵活。

**如果我们的业务上，关单时长刚好和RocketMQ延迟消息支持的时长匹配的话，那么是可以基于RocketMQ延迟消息来实现的。否则，这种方式并不是最佳的。（但是在RocketMQ 5.0中新增了基于时间轮实现的定时消息，可以解决这个问题！）**



**RabbitMQ死信队列**

延迟消息不仅在RocketMQ中支持，其实在RabbitMQ中也是可以实现的，只不过其底层是基于死信队列实现的。

当RabbitMQ中的一条正常的消息，因为过了存活时间（TTL过期）、队列长度超限、被消费者拒绝等原因无法被消费时，就会变成Dead Message，即死信。

当一个消息变成死信之后，他就能被重新发送到死信队列中（其实是交换机-exchange）。

那么基于这样的机制，就可以实现延迟消息了。那就是我们给一个消息设定TTL，但是并不消费这个消息，等他过期，过期后就会进入到死信队列，然后我们再监听死信队列的消息消费就行了。

而且，RabbitMQ中的这个TTL是可以设置任意时长的，这就解决了RocketMQ的不灵活的问题。

缺点：

-   **队头阻塞**：但是，死信队列的实现方式存在一个问题，那就是可能造成队头阻塞，如果死信队列中的队头的消息一直无法消费成功，那么就会阻塞整个队列，这时候即使排在他后面的消息过期需要处理了，那么也会被一直阻塞。

**基于RabbitMQ的死信队列，可以实现延迟消息，非常灵活的实现定时关单，并且借助RabbitMQ的集群扩展性，可以实现高可用，以及处理大并发量。他的缺点第一是可能存在消息阻塞的问题，还有就是方案比较复杂，不仅要依赖RabbitMQ，而且还需要声明很多队列(exchange)出来，增加系统的复杂度。**



**RabbitMQ插件**

其实，基于RabbitMQ的话，可以不用死信队列也能实现延迟消息，那就是基于rabbitmq_delayed_message_exchange插件，这种方案能够解决通过死信队列实现延迟消息出现的消息阻塞问题。但是该插件从RabbitMQ的3.6.12开始支持的，所以对版本有要求。

这个插件是官方出的，可以放心使用，安装并启用这个插件之后，就可以创建x-delayed-message类型的队列了。



前面我们提到的基于死信队列的方式，是消息先会投递到一个正常队列，在TTL过期后进入死信队列。但是基于插件的这种方式，消息并不会立即进入队列，而是先把他们保存在一个基于Erlang开发的Mnesia数据库中，然后通过一个定时器去查询需要被投递的消息，再把他们投递到x-delayed-message队列中。

**基于RabbitMQ插件的方式可以实现延迟消息，并且不存在消息阻塞的问题，但是因为是基于插件的，而这个插件支持的最大延长时间是(2^32)-1 毫秒，大约49天，超过这个时间就会被立即消费。但是他基于RabbitMQ实现，所以在可用性、性能方便都很不错**



**Redis过期监听**

很多用过Redis的人都知道，Redis有一个过期监听的功能

在 redis.conf 中，加入一条配置`notify-keyspace-events Ex`开启过期监听，然后再代码中实现一个KeyExpirationEventMessageListener，就可以监听key的过期消息了。

这样就可以在接收到过期消息的时候，进行订单的关单操作。

缺点：

-   这个方案不建议大家使用，是因为Redis官网上明确的说过，Redis并不保证Key在过期的时候就能被立即删除，更不保证这个消息能被立即发出。所以，消息延迟是必然存在的，随着数据量越大延迟越长，延迟个几分钟都是常事儿。

而且，在Redis 5.0之前，这个消息是通过PUB/SUB模式发出的，他不会做持久化，至于你有没有接到，有没有消费成功，他不管。也就是说，如果发消息的时候，你的客户端挂了，之后再恢复的话，这个消息你就彻底丢失了。（在Redis 5.0之后，因为引入了Stream，是可以用来做延迟消息队列的。）



**Redis的zset**

虽然基于Redis过期监听的方案并不完美，但是并不是Redis实现关单功能就不完美了，还有其他的方案。

>   我们可以借助Redis中的有序集合——zset来实现这个功能。
>
>   zset是一个有序集合，每一个元素(member)都关联了一个 score，可以通过 score 排序来取集合中的值。

我们将订单超时时间的时间戳（下单时间+超时时长）与订单号分别设置为 score 和 member。这样redis会对zset按照score延时时间进行排序。然后我们再开启redis扫描任务，获取**"当前时间 > score"的延时任务**，扫描到之后取出订单号，然后查询到订单进行关单操作即可。

**使用redis zset来实现订单关闭的功能的优点是可以借助redis的持久化、高可用机制。避免数据丢失。但是这个方案也有缺点，那就是在高并发场景中，有可能有多个消费者同时获取到同一个订单号，一般采用加分布式锁解决，但是这样做也会降低吞吐型。**

但是，在大多数业务场景下，如果幂等性做得好的，多个消费者取到同一个订单号也无妨。



**Redisson + Redis**

Redisson是一个在Redis的基础上实现的框架，它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。

Redisson中定义了分布式延迟队列**RDelayedQueue**，这是一种基于我们前面介绍过的zset结构实现的延时队列，它允许以指定的延迟时长将元素放到目标队列中。

其实就是在zset的基础上增加了一个基于内存的延迟队列。当我们要添加一个数据到延迟队列的时候，redisson会把数据+超时时间放到zset中，并且起一个延时任务，当任务到期的时候，再去zset中把数据取出来，返回给客户端使用。

>   大致思路就是这样的，感兴趣的大家可以看一看RDelayedQueue的具体实现。

**基于Redisson的实现方式，是可以解决基于zset方案中的并发重复问题的，而且还能实现方式也比较简单，稳定性、性能都比较高。**



## 让你实现一个分布式单例对象，怎么设计？



## 商家想要知道自己店铺最好的top50商品，如何实现？



## 朋友圈点赞功能实现？



## 抖音点赞功能实现？



## 分布式锁一般怎么实现？



## 如何设计一个分布式ID分号器？



## 如果让你统计每个接口每分钟调用的次数怎么统计？



## 线上消息队列故障，兜底改造方案？



## 一笔订单，在取消的那一刻用户刚好付款了，怎么办？



## 项目上发现出现很多重复订单，怎么处理？



## 线上发现Redis机器爆了，如何优化？



## 项目上需要导入一个几百万数据excel文件到数据库，有哪些注意点？



## 如果一笔订单，用户同时在微信和支付宝同时支付，会怎么样？



## 假设有一个1G大的HashMap，此时用户请求过来刚好触发它的扩容，会怎么样？怎么优化？



## 项目中如何设置远程调用的超时时间？



## 从网关再到各个微服务，如何设置RPC的超时时间。要考虑哪些问题？



## 如果没有内存限制，如何快速、安全地将1000亿条数据插入到HashMap中？



## 忘记密码后为什么是重置密码，而不是告知原密码？

因为服务端也无法得知原密码是啥

服务端在保存密码到数据库的时候，绝对不能直接铭文存储，铭文存储有以下风险:

-   数据库数据被盗风险
-   服务端相关人员恶意盗用等。。

通常我们将密码进行哈希加密，哈希算法是不可逆的，因此服务端也不知道我们的原密码是啥

常见的哈希算法：

-   MD5
-   SHA-256
-   Bcrypt

MD5，不同的密码加密后可能会产生相同的哈希值（即哈希冲突）

SHA-256，不同的密码加密后哈希冲突的可能性极低，比MD5抗碰撞性更强

MD5、SHA-256每次加密同一个密码都是固定的密文，可能存在暴力破解的风险，因此通常会采用SHA-256+盐的方式进行加密

>   盐：salt，即只要我们程序员才做到的字符串，可以有效的防止暴力破解

Bcrypt，自带盐，且每次加密盐都不一样，加密同一个密码可能得到的密文不一样，因此能够防止暴力破解



## 三次输错密码后，系统是这么做到不让我继续尝试的？





## 如何保证接口幂等性？



## 百万数据导出



## 10亿数据中如何实现URL去重？



# 智商题

## 如何在2G大小的文件中，找出高频top100的单词？

>   这是一个`Top K`问题，面试过程中，可能会有很多变体
>
>   这类问题是典型的开放式题目，没有标准答案。

这个题目面临两个问题：

1、2G大小的文件，那就意味着无法一次性地加载到内存中

2、如果采用常规的思维，需要从这么大的文件中筛选，它会非常慢



我们可以采用分割（分治）的思想，将2G大小文件分割为每块大小512KB的小文件，那么就是2048个小文件。避免一次性读取整个文件造成内存不足的问题。

接着我们可以定义一个长度为2048的hash表数组，用来统计每个小文件中单词出现的频率。

我们还可以使用多线程去并发遍历2048个小文件，针对每个单词进行hash取模运算，分别存储到长度为2048的hash表数组中。

```java
int hash = Math.abs(word.hashCode() % hashTableSize);
hashTables[hash].merge(word, 1, Integer::sum);
```

接着我们遍历这个长度为2048的hash表数组，把频率为前100的单词存入到小顶堆中。小顶堆中的单词就是top100的单词





# 经验

## Lombok使用技巧

开发中，如果想使用Lombok建造者模式来set属性，如下：

```java
@Data
@Builder	// @Data @Builder 与同时使用时，需要加上无参、满参注解
@AllArgsConstructor	
@NoArgsConstructor
public class OssReq {
    @ApiModelProperty(value = "文件存储路径")
    private String filePath;
    @ApiModelProperty(value = "文件名")
    private String fileName;
    @ApiModelProperty(value = "请求的uid")
    private Long uid;
    @ApiModelProperty(value = "自动生成地址")
    @Builder.Default	// 切记！！！
    private boolean autoPath = true;
}
```

